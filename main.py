#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ë©€í‹°ëª¨ë‹¬(ë¬¼ì²´ ì¸ì‹/ìŒì„±) + YOLO í¬ì¦ˆ íŠ¸ë˜í‚¹ ë©”ì¸
"""

from __future__ import annotations

import argparse
import time
from typing import Optional

import cv2
import numpy as np
import rclpy
import threading

import DR_init

from robot_controller import MultiModalRobotController, ROBOT_ID
from object_mapper import ObjectMapper
from realtime_client import RealtimeImageVoiceClient, test_microphone
from vision_module import Tracker, project_point, get_3d_bbox
from yolo_hand_robot_control import YoloHandRobotControl
from common_utils import safe_imshow, wait_for_camera_stream
from config import APP_CONFIG


def run_yolo_pose_phase(yolo_node: Optional[YoloHandRobotControl]) -> None:
    """íƒ€ê²Ÿ ìœ„ì¹˜ ì´ë™ í›„ YOLO í¬ì¦ˆ íŠ¸ë˜í‚¹ ë‹¨ê³„."""
    if yolo_node is None:
        return

    print("\nğŸ¯ íƒ€ê²Ÿ ë„ë‹¬ â†’ YOLO í¬ì¦ˆ íŠ¸ë˜í‚¹ í™œì„±í™”")
    yolo_node.enable_tracking()
    completed = yolo_node.wait_for_exit_sequence(timeout=APP_CONFIG.yolo.overall_timeout)
    if completed:
        print("âœ… í¬ì¦ˆ ê¸°ë°˜ ë°ë“œì¡´ ì²˜ë¦¬ ì™„ë£Œ (ê·¸ë¦¬í¼ ê°œë°© ë° í™ˆ ë³µê·€ í™•ì¸)")
    else:
        print("âš ï¸  í¬ì¦ˆ íŠ¸ë˜í‚¹ íƒ€ì„ì•„ì›ƒ â€“ ë‹¤ìŒ ì‚¬ì´í´ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
        yolo_node.disable_tracking()


def run_multimodal_loop(controller, mapper, realtime_client, yolo_node, args):
    """ë©€í‹°ëª¨ë‹¬ ìë™ ë£¨í”„ ì‹¤í–‰ (YOLO í¬ì¦ˆ íŠ¸ë˜í‚¹ í¬í•¨)"""
    if realtime_client is None:
        print("âŒ Realtime í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. --disable-multimodal ì˜µì…˜ì„ í•´ì œí•´ì£¼ì„¸ìš”.")
        return
    main_window = "Real-time Object Tracking"
    snapshot_window = "Snapshot - Annotated"
    ai_window = "Snapshot - Original (AI)"

    # ìœˆë„ìš° ìƒì„± ìƒíƒœ ì¶”ì 
    windows_created = False

    try:
        # ëª¨ë“  ìœˆë„ìš°ë¥¼ ë¯¸ë¦¬ ìƒì„± (í•œ ë²ˆë§Œ)
        cv2.namedWindow(main_window, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(main_window, 1280, 720)
        cv2.moveWindow(main_window, 0, 0)

        cv2.namedWindow(snapshot_window, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(snapshot_window, 640, 480)
        cv2.moveWindow(snapshot_window, 0, 750)

        cv2.namedWindow(ai_window, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(ai_window, 640, 480)
        cv2.moveWindow(ai_window, 650, 750)

        windows_created = True
        print("âœ… GUI ìœˆë„ìš° ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  ìœˆë„ìš° ìƒì„± ì˜¤ë¥˜: {e}")
        return

    print("\nğŸ“¸ ì‹¤ì‹œê°„ ë¬¼ì²´ ì¶”ì  ì‹œì‘. Ctrl+C ë˜ëŠ” ESCë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")

    # Tracker ì´ˆê¸°í™”
    tracker = Tracker(max_age=APP_CONFIG.vision.tracker_max_age, dist_thresh=APP_CONFIG.vision.tracker_dist_thresh)
    tracked_objects = {}
    last_detection_time = 0.0
    detection_interval = APP_CONFIG.vision.detection_interval

    # ìƒíƒœ ë³€ìˆ˜
    waiting_for_snapshot = True
    cycle_in_progress = False
    gui_update_active = False

    def reset_tracking_state():
        nonlocal tracker, tracked_objects
        tracker = Tracker(max_age=APP_CONFIG.vision.tracker_max_age,
                          dist_thresh=APP_CONFIG.vision.tracker_dist_thresh)
        tracked_objects = {}
        controller.detected_objects = []
        if hasattr(controller, '_tracking_logged'):
            delattr(controller, '_tracking_logged')
        if hasattr(controller, '_bbox_error_logged'):
            delattr(controller, '_bbox_error_logged')

    # ë‹¨ì¼ ìŠ¤ë ˆë“œ GUI: ë©”ì¸ ë£¨í”„ì—ì„œë§Œ cv2 ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•œë‹¤.
    def pump_gui():
        """ìœˆë„ìš° ì´ë²¤íŠ¸ ìµœì†Œ ì²˜ë¦¬"""
        cv2.waitKey(1)

    # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ìœˆë„ìš° ì´ˆê¸°í™”
    dummy_img = np.zeros((480, 640, 3), dtype=np.uint8)
    cv2.putText(dummy_img, "Waiting for snapshot...", (50, 240),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    safe_imshow(snapshot_window, dummy_img)
    safe_imshow(ai_window, dummy_img)

    # ë©”ì¸ ìœˆë„ìš°ì—ë„ ì´ˆê¸° ì´ë¯¸ì§€ í‘œì‹œ
    if controller.latest_cv_color is not None:
        safe_imshow(main_window, controller.latest_cv_color)

    # ìœˆë„ìš°ê°€ ì™„ì „íˆ ìƒì„±ë˜ë„ë¡ ëŒ€ê¸°
    for _ in range(10):
        cv2.waitKey(10)

    while rclpy.ok() and not controller.should_exit:
        # ì‹¤ì‹œê°„ ë¬¼ì²´ ê°ì§€ ë° ì¶”ì 
        current_time = time.time()
        if (not controller.is_robot_moving and
            controller.latest_cv_color is not None and
            controller.latest_cv_depth_mm is not None and
            controller.intrinsics is not None and
            (current_time - last_detection_time) >= detection_interval):

            try:
                detections = controller.detect_objects()
                if len(detections) > 0:
                    tracked_objects = tracker.update(detections)
                    controller.detected_objects = list(tracked_objects.values())
                    # ë””ë²„ê¹…: ì¶”ì  ì¤‘ì¸ ê°ì²´ í™•ì¸
                    if len(tracked_objects) > 0 and not hasattr(controller, '_tracking_logged'):
                        print(f"âœ… ì¶”ì  ì¤‘: {len(tracked_objects)}ê°œ ê°ì²´")
                        controller._tracking_logged = True
                else:
                    # ê°ì§€ëœ ë¬¼ì²´ê°€ ì—†ìœ¼ë©´ ì´ì „ íŠ¸ë˜í‚¹ ì •ë³´ë„ ì¦‰ì‹œ ì´ˆê¸°í™”í•˜ì—¬ ì”ìƒ ì œê±°
                    tracked_objects = {}
                    tracker.objects.clear()
                    controller.detected_objects = []
                    if hasattr(controller, '_tracking_logged'):
                        delattr(controller, '_tracking_logged')
                last_detection_time = current_time
            except Exception as e:
                # ê°ì§€ ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                if "Connection reset" in str(e):
                    print(f"âš ï¸  ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
                last_detection_time = current_time

        # ì‹¤ì‹œê°„ íŠ¸ë˜í‚¹ í™”ë©´ í‘œì‹œ (í•­ìƒ ì—…ë°ì´íŠ¸)
        if controller.latest_cv_color is not None:
            display_frame = controller.latest_cv_color.copy()
            h, w, _ = display_frame.shape

            # ì¶”ì  ì¤‘ì¸ ë¬¼ì²´ì— 6D ë°•ìŠ¤ 2D í”„ë¡œì ì…˜(ID ë¼ë²¨ 1ë²ˆë¶€í„°)ë§Œ í‘œì‹œ
            if tracked_objects and controller.intrinsics is not None:
                fx, fy = controller.intrinsics.fx, controller.intrinsics.fy
                cx, cy = controller.intrinsics.ppx, controller.intrinsics.ppy

                for oid, obj in tracked_objects.items():
                    display_id = oid + 1
                    Xo, Yo, Zo = obj["x"], obj["y"], obj["z"]
                    lx = obj.get("lx", obj.get("length", 0.05))
                    ly = obj.get("ly", obj.get("length", 0.05))

                    try:
                        box = get_3d_bbox(Xo, Yo, Zo, obj["yaw"], lx, ly)
                        pts = []
                        for p in box:
                            pr = project_point(p, fx, fy, cx, cy)
                            if pr is not None:
                                pts.append(pr)

                        if len(pts) == 4:
                            # 3D ë°•ìŠ¤ í”„ë¡œì ì…˜ ê·¸ë¦¬ê¸°
                            for i in range(4):
                                cv2.line(display_frame, pts[i], pts[(i+1)%4], (0, 255, 0), 2)

                            # ID ë¼ë²¨
                            label_pos = (pts[0][0], max(10, pts[0][1] - 10))
                            cv2.putText(
                                display_frame, f"ID-{display_id:02d}", label_pos,
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2
                            )

                            # ì¤‘ì‹¬ì  í‘œì‹œ
                            if Zo > 0:
                                center_u = int(Xo * fx / Zo + cx)
                                center_v = int(Yo * fy / Zo + cy)
                                if 0 <= center_u < w and 0 <= center_v < h:
                                    cv2.circle(display_frame, (center_u, center_v), 4, (0, 255, 255), -1)
                    except Exception as e:
                        if not hasattr(controller, '_bbox_error_logged'):
                            print(f"âš ï¸  ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
                            controller._bbox_error_logged = True

            # í™”ë©´ ì¤‘ì‹¬ì  í‘œì‹œ
            cv2.circle(display_frame, (w // 2, h // 2), 5, (0, 0, 255), -1)
            cv2.line(display_frame, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 0, 255), 2)
            cv2.line(display_frame, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 0, 255), 2)

            # ìƒíƒœ í‘œì‹œ
            if controller.is_robot_moving:
                status_text = "ROBOT MOVING..."
                color = (0, 0, 255)
            elif cycle_in_progress:
                status_text = "AI PROCESSING..."
                color = (255, 165, 0)
            elif waiting_for_snapshot:
                status_text = "TRACKING - Ready for snapshot"
                color = (255, 255, 0)
            else:
                status_text = "Ready"
                color = (0, 255, 0)

            cv2.rectangle(display_frame, (5, 5), (500, 95), (0, 0, 0), -1)
            cv2.rectangle(display_frame, (5, 5), (500, 95), color, 2)
            cv2.putText(display_frame, status_text, (15, 40),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

            # ì¶”ì  ì¤‘ì¸ ê°ì²´ ìˆ˜
            if tracked_objects:
                obj_text = f"Tracking: {len(tracked_objects)} objects"
                cv2.putText(display_frame, obj_text, (15, 75),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                cv2.putText(display_frame, "No objects detected", (15, 75),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            safe_imshow(main_window, display_frame)

        # GUI ì´ë²¤íŠ¸ ì²˜ë¦¬ (ë” ì§§ì€ ì£¼ê¸°ë¡œ)
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            print("\nâœ“ ESC í‚¤ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
            controller.should_exit = True
            break

        # ìŠ¤ëƒ…ìƒ· ì´¬ì˜ ëŒ€ê¸° ì¤‘ì¼ ë•Œ
        if waiting_for_snapshot and not cycle_in_progress and not controller.is_robot_moving:
            if len(tracked_objects) == 0:
                time.sleep(0.1)
                continue

            print("\nğŸ”„ AIì—ê²Œ ìŠ¤ëƒ…ìƒ· ì´¬ì˜ í—ˆê°€ ìš”ì²­ ì¤‘...")
            cycle_in_progress = True
            waiting_for_snapshot = False

            try:
                pump_gui()
                # AIê°€ "ìŠ¤ëƒ…ìƒ·ì„ ì°ì„ê¹Œìš”?" ë¬¼ì–´ë´„
                should_take_snapshot = realtime_client.ask_snapshot_permission()

                if not should_take_snapshot:
                    print("âš ï¸  ìŠ¤ëƒ…ìƒ· ì´¬ì˜ ì·¨ì†Œë¨")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    time.sleep(APP_CONFIG.vision.snapshot_wait)
                    continue

                print("\nğŸ“¸ ìŠ¤ëƒ…ìƒ· ì´¬ì˜ ì¤‘...")

                # ìŠ¤ëƒ…ìƒ· ì§ì „ì— ë‹¤ì‹œ ê°ì§€í•´ ìµœì‹  ìœ„ì¹˜ë§Œ ë°˜ì˜
                try:
                    detections_now = controller.detect_objects()
                    if len(detections_now) == 0:
                        print("âš ï¸  ìŠ¤ëƒ…ìƒ· ì‹œì ì— ê°ì§€ëœ ë¬¼ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        waiting_for_snapshot = True
                        cycle_in_progress = False
                        time.sleep(APP_CONFIG.vision.snapshot_wait)
                        continue
                    tracked_objects = tracker.update(detections_now)
                    controller.detected_objects = list(tracked_objects.values())
                except Exception as detect_exc:
                    print(f"âš ï¸  ìŠ¤ëƒ…ìƒ· ì§ì „ ì¬ê°ì§€ ì‹¤íŒ¨: {detect_exc}")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    time.sleep(APP_CONFIG.vision.snapshot_wait)
                    continue

                # í˜„ì¬ ì¶”ì  ì¤‘ì¸ ë¬¼ì²´ë¥¼ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ë³€í™˜
                color_frame = controller.latest_cv_color.copy()
                detections = []
                fx, fy = controller.intrinsics.fx, controller.intrinsics.fy
                cx, cy = controller.intrinsics.ppx, controller.intrinsics.ppy

                for oid, obj in tracked_objects.items():
                    obj_copy = obj.copy()
                    dist = np.sqrt(obj_copy["x"]**2 + obj_copy["y"]**2)
                    obj_copy["distance_from_center"] = dist

                    # í”½ì…€ ì¢Œí‘œ ê³„ì‚°
                    if "pixel_u" not in obj_copy and obj_copy["z"] > 0:
                        obj_copy["pixel_u"] = int(obj_copy["x"] * fx / obj_copy["z"] + cx)
                        obj_copy["pixel_v"] = int(obj_copy["y"] * fy / obj_copy["z"] + cy)

                    # bbox
                    if "bbox_min_u" not in obj_copy and "pixel_u" in obj_copy:
                        obj_copy["bbox_min_u"] = obj_copy["pixel_u"] - 50
                        obj_copy["bbox_max_u"] = obj_copy["pixel_u"] + 50
                        obj_copy["bbox_min_v"] = obj_copy["pixel_v"] - 50
                        obj_copy["bbox_max_v"] = obj_copy["pixel_v"] + 50

                    # length í•„ë“œ í†µì¼
                    if "length" not in obj_copy and "ly" in obj_copy:
                        obj_copy["length"] = obj_copy["ly"]

                    detections.append(obj_copy)

                detections = sorted(detections, key=lambda x: x["distance_from_center"])

                # ê°ì§€ëœ ê°ì²´ ì •ë³´ ì¶œë ¥
                print("\n" + "=" * 80)
                print(f"ğŸ” ìŠ¤ëƒ…ìƒ·ì— í¬í•¨ëœ ë¬¼ì²´: {len(detections)}ê°œ")
                print("=" * 80)
                for idx, obj in enumerate(detections, start=1):
                    print(f"  ğŸ“¦ OBJ-{idx:02d}:")
                    print(f"     ìœ„ì¹˜: ({obj['x']:.3f}, {obj['y']:.3f}, {obj['z']:.3f})m")
                    print(f"     íšŒì „: {np.degrees(obj['yaw']):.1f}Â°")
                    print(f"     í¬ê¸°: {obj.get('length', obj.get('ly', 0))*1000:.0f}mm")
                print("=" * 80 + "\n")

                # ìŠ¤ëƒ…ìƒ· ìƒì„±
                snapshot = mapper.build_snapshot(color_frame, detections)
                if snapshot is None:
                    print("âš ï¸  ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹¤íŒ¨")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    continue

                # ìŠ¤ëƒ…ìƒ· ì €ì¥ ë° í‘œì‹œ (ì´ë¯¸ ìƒì„±ëœ ìœˆë„ìš°ì— ì—…ë°ì´íŠ¸)
                safe_imshow(snapshot_window, snapshot.annotated_frame)
                safe_imshow(ai_window, snapshot.original_frame)

                # ìŠ¤ëƒ…ìƒ· ì €ì¥
                snapshot_dir = APP_CONFIG.paths.snapshot_dir
                snapshot_dir.mkdir(parents=True, exist_ok=True)
                timestamp = int(time.time())

                original_path = snapshot_dir / f"snapshot_original_{timestamp}.jpg"
                cv2.imwrite(str(original_path), snapshot.original_frame)

                annotated_path = snapshot_dir / f"snapshot_annotated_{timestamp}.jpg"
                cv2.imwrite(str(annotated_path), snapshot.annotated_frame)

                print(f"ğŸ’¾ ìŠ¤ëƒ…ìƒ· ì €ì¥: {original_path.name}, {annotated_path.name}")

                # AIì—ê²Œ ë¬¼ì²´ ë¶„ì„ ë° ì„ íƒ ìš”ì²­
                try:
                    pump_gui()
                    decision = realtime_client.request_pick_label(
                        mapper=mapper,
                        snapshot=snapshot,
                        max_turns=args.realtime_turns,
                    )
                except Exception as exc:
                    print(f"âŒ Realtime API í†µì‹  ì‹¤íŒ¨: {exc}")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    continue

                if not decision.label:
                    print("âš ï¸  ìœ íš¨í•œ PICK_LABELì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    continue

                target = snapshot.find_object(decision.label)
                if target is None:
                    print(f"âš ï¸  {decision.label}ì— í•´ë‹¹í•˜ëŠ” ë¬¼ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    waiting_for_snapshot = True
                    cycle_in_progress = False
                    continue

                print(f"\nâœ… ì„ íƒëœ ëŒ€ìƒ: {target.label}")

                # ë¬¼ì²´ ì§‘ê¸°
                success = controller.pick_object(target.raw)
                if success:
                    print(f"\nâœ… {ObjectMapper.format_decision_message(target)}")

                    delivery_choice = "person"
                    picked_description = decision.transcript.strip() if decision and decision.transcript else target.label
                    if realtime_client is not None:
                        try:
                            delivery_choice = realtime_client.request_delivery_destination(picked_description)
                            print(f"ğŸ—£ï¸ ì „ë‹¬ ëŒ€ìƒ ì„ íƒ: {delivery_choice}")
                        except Exception as exc:
                            print(f"âš ï¸  ì „ë‹¬ ëŒ€ìƒ ì§ˆì˜ ì‹¤íŒ¨: {exc}. ê¸°ë³¸ê°’(person) ì‚¬ìš©")

                    if delivery_choice == "basket":
                        controller.place_object_in_basket()
                    else:
                        controller.place_object_at_target(open_gripper=False, return_home=False)
                        if not args.disable_yolo_pose:
                            run_yolo_pose_phase(yolo_node)

                    print("âœ… ì‚¬ì´í´ ì™„ë£Œ! ë‹¤ìŒ ì‚¬ì´í´ ëŒ€ê¸° ì¤‘...\n")
                else:
                    print("âš ï¸  ë¬¼ì²´ ì§‘ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                # ë‹¤ìŒ ì‚¬ì´í´ ì¤€ë¹„
                waiting_for_snapshot = True
                cycle_in_progress = False
                reset_tracking_state()

                # ì§§ì€ ëŒ€ê¸° í›„ ë°”ë¡œ ë‹¤ìŒ ì‚¬ì´í´ë¡œ
                print("â³ ë‹¤ìŒ ì‚¬ì´í´ ì¤€ë¹„ ì¤‘...\n")
                time.sleep(1.0)

            except KeyboardInterrupt:
                print("\nâš ï¸  ì‚¬ì´í´ ì¤‘ Ctrl+C ê°ì§€")
                controller.should_exit = True
                break
            except Exception as e:
                print(f"âŒ ì‚¬ì´í´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                waiting_for_snapshot = True
                cycle_in_progress = False
                reset_tracking_state()

                time.sleep(1.0)

    # ìœˆë„ìš° ëª…ì‹œì ìœ¼ë¡œ ë‹«ê¸°
    print("GUI ìœˆë„ìš° ì •ë¦¬ ì¤‘...")
    try:
        # GUI ìŠ¤ë ˆë“œê°€ ìˆë‹¤ë©´ ë¨¼ì € ì •ì§€
        if 'gui_update_active' in locals():
            gui_update_active = False
        if 'gui_thread' in locals() and gui_thread.is_alive():
            gui_thread.join(timeout=2.0)

        # ìœˆë„ìš° ë‹«ê¸°
        if windows_created:
            cv2.destroyWindow(main_window)
            cv2.destroyWindow(snapshot_window)
            cv2.destroyWindow(ai_window)
            for _ in range(5):
                cv2.waitKey(1)
    except Exception as e:
        print(f"âš ï¸  ìœˆë„ìš° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
    finally:
        cv2.destroyAllWindows()
        cv2.waitKey(1)


def main():
    parser = argparse.ArgumentParser(description="Multi-Modal Robot Control System (with YOLO pose)")

    parser.add_argument("--disable-multimodal", action="store_true", help="Realtime ì—°ë™ ë¹„í™œì„±í™”")
    parser.add_argument("--text-input-only", action="store_true", help="ë§ˆì´í¬ ëŒ€ì‹  í…ìŠ¤íŠ¸ ì…ë ¥")
    parser.add_argument("--play-audio-responses", action="store_true", help="AI ìŒì„± ì‘ë‹µ ì¬ìƒ")
    parser.add_argument("--realtime-model", type=str, default=APP_CONFIG.realtime.model, help="Realtime API ëª¨ë¸")
    parser.add_argument("--realtime-turns", type=int, default=APP_CONFIG.realtime.max_turns, help="í•œ ëª…ë ¹ ë‹¹ í—ˆìš© í„´ ìˆ˜")
    parser.add_argument("--operator-audio-seconds", type=int, default=APP_CONFIG.realtime.operator_audio_seconds, help="ëª…ë ¹ ë…¹ìŒ ì‹œê°„(ì´ˆ)")
    parser.add_argument("--realtime-debug-events", action="store_true", help="Realtime ì´ë²¤íŠ¸ ë¡œê·¸ ì¶œë ¥")
    parser.add_argument("--skip-mic-test", action="store_true", help="ë§ˆì´í¬ ì‚¬ì „ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--disable-yolo-pose", dest="disable_yolo_pose", action="store_true", help="YOLO í¬ì¦ˆ íŠ¸ë˜í‚¹ ë¹„í™œì„±í™”")

    args = parser.parse_args()

    # ë§ˆì´í¬ í…ŒìŠ¤íŠ¸
    if (not args.text_input_only and
        not args.disable_multimodal and
        not args.skip_mic_test):
        if not test_microphone():
            print("\nâŒ ë§ˆì´í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   --skip-mic-test ë˜ëŠ” --text-input-only ì˜µì…˜ìœ¼ë¡œ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return

    # ROS2 ì´ˆê¸°í™”
    rclpy.init(args=None)

    # DSR ë…¸ë“œ ìƒì„±
    dsr_node = rclpy.create_node("dsr_node", namespace=ROBOT_ID)
    DR_init.__dsr__node = dsr_node

    # DSR_ROBOT2 ë¼ì´ë¸ŒëŸ¬ë¦¬ import
    try:
        from DSR_ROBOT2 import wait, get_current_posj, movej, movel
        from DR_common2 import posj, posx
    except ImportError as e:
        print(f"âŒ DSR_ROBOT2 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        dsr_node.destroy_node()
        rclpy.shutdown()
        return

    # ì»¨íŠ¸ë¡¤ëŸ¬ ìƒì„±
    controller = MultiModalRobotController(APP_CONFIG)

    # ObjectMapper ìƒì„±
    mapper = ObjectMapper()

    # Realtime í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    realtime_client = None
    if not args.disable_multimodal:
        try:
            realtime_client = RealtimeImageVoiceClient(
                model=args.realtime_model,
                operator_audio_seconds=args.operator_audio_seconds,
                use_microphone=not args.text_input_only,
                play_audio=args.play_audio_responses,
                debug_events=args.realtime_debug_events,
            )
            print("âœ… Realtime multimodal í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
        except Exception as exc:
            print(f"âŒ Realtime í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}")
            args.disable_multimodal = True

    # YOLO í¬ì¦ˆ ë…¸ë“œ ìƒì„± (í•„ìš” ì‹œ)
    yolo_node = None
    if not args.disable_yolo_pose:
        try:
            yolo_node = YoloHandRobotControl(APP_CONFIG, realtime_client=realtime_client)
            print("âœ… YOLO í¬ì¦ˆ íŠ¸ë˜ì»¤ ì¤€ë¹„ ì™„ë£Œ")
        except Exception as exc:
            print(f"âš ï¸  YOLO í¬ì¦ˆ íŠ¸ë˜ì»¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}")
            args.disable_yolo_pose = True
            yolo_node = None

    # ì¹´ë©”ë¼ ë°ì´í„° ëŒ€ê¸°
    # ë©€í‹°ìŠ¤ë ˆë“œ executorë¡œ ì¹´ë©”ë¼ ì½œë°±ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ëŒë¦¼
    executor = rclpy.executors.MultiThreadedExecutor()
    executor.add_node(controller)
    executor.add_node(dsr_node)
    if yolo_node:
        executor.add_node(yolo_node)

    spin_thread = threading.Thread(target=executor.spin, daemon=True)
    spin_thread.start()

    if not wait_for_camera_stream(controller):
        controller.terminate_gripper()
        controller.destroy_node()
        if yolo_node:
            yolo_node.destroy_node()
        dsr_node.destroy_node()
        executor.shutdown()
        spin_thread.join(timeout=1.0)
        cv2.destroyAllWindows()
        rclpy.shutdown()
        return

    try:
        run_multimodal_loop(controller, mapper, realtime_client, yolo_node, args)
    except KeyboardInterrupt:
        print("\n\nCtrl+Cë¡œ ì¢…ë£Œ...")
    finally:
        print("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ ì¤‘...")
        controller.terminate_gripper()
        cv2.destroyAllWindows()
        controller.destroy_node()
        if yolo_node:
            yolo_node.destroy_node()
        dsr_node.destroy_node()
        executor.shutdown()
        spin_thread.join(timeout=1.0)
        if rclpy.ok():
            rclpy.shutdown()
        print("âœ“ ì¢…ë£Œ ì™„ë£Œ")


if __name__ == "__main__":
    main()
